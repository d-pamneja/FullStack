{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and chunking the Data\n",
    "Here, we will use the PyPDFDirectoryLoader for the PDF from the langchain wrapper to load the PDF data and chunk it into paragraphs. First step includes loading the current PDF file into the loader and converting it to a list of documents. Each document is a list of pages, which consists the metadata of the source PDF and the page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Project\\nReport\\nSPG\\nGroup\\nProject\\nJan\\n2024\\nCommunication\\nand\\nListening\\nSkills\\nTeam\\n5\\nTeam\\nMembers\\nHari\\nPrapan\\n(21f3002087)\\nPragya\\nSingh\\n(21f3001204)\\nVisist\\nTallam\\n(21f2001553)\\nUllas\\nKumar\\n(21f3002619)\\nDhruv\\nPamneja\\n(21f1001719)\\n', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 0}),\n",
       " Document(page_content=\"Abstract\\nThe\\nproject\\nfocuses\\non\\nexploring\\nthe\\ncritical\\nimportance\\nof\\ncommunication\\nand\\nlistening\\nskills\\nwithin\\nthe\\ncorporate\\nworld.\\nIt\\ndelves\\ninto\\nthe\\nfoundational\\nrole\\nthese\\nskills\\nplay\\nin\\norganizational\\nsuccess,\\nimpacting\\nareas\\nsuch\\nas\\nemployee\\nengagement,\\nteam\\ncollaboration,\\nand\\noverall\\nproductivity.\\nThe\\ndecision\\nto\\ninvestigate\\nthis\\ntopic\\nstems\\nfrom\\nits\\nrelevance\\nin\\ntoday's\\nfast-paced\\nbusiness\\nlandscape,\\nwhere\\neffective\\ncommunication\\nis\\nvital\\nfor\\nnavigating\\ncomplex\\nenvironments\\nand\\nachieving\\norganizational\\ngoals.\\nBy\\nconducting\\nsemi-structured\\ninterviews\\nwith\\nprofessionals\\nand\\nextensively\\nresearching\\nrelevant\\nliterature,\\nthe\\nproject\\naims\\nto\\nprovide\\nvaluable\\ninsights\\nand\\npractical\\nrecommendations\\nfor\\nenhancing\\ncommunication\\npractices\\nin\\ncorporate\\nsettings.\\nThe\\nconceptual\\nframework\\noutlines\\nkey\\nstrategies\\nfor\\nimproving\\ncommunication\\neffectiveness,\\nleadership\\ndevelopment,\\nand\\ncontinuous\\nmonitoring\\nand\\nimprovement.\\nThrough\\ncollaborative\\nefforts,\\nthe\\nproject\\ncontributes\\nto\\na\\ndeeper\\nunderstanding\\nof\\ncommunication\\ndynamics\\nand\\nfosters\\na\\nculture\\nof\\ncommunication\\nexcellence\\nwithin\\norganizations.\", metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 1}),\n",
       " Document(page_content=\"Topic\\nSelection\\nOur\\nteam\\nhas\\nselected\\nthe\\ntopic\\nof\\ncommunication\\nand\\nlistening\\nskills\\nin\\nthe\\ncorporate\\nworld\\ndue\\nto\\nits\\nparamount\\nimportance\\nin\\nmodern-day\\nworkplaces.\\nEffective\\ncommunication\\nand\\nactive\\nlistening\\nare\\nfoundational\\npillars\\nof\\norganizational\\nsuccess,\\nimpacting\\nvarious\\naspects\\nsuch\\nas\\nemployee\\nengagement,\\nteam\\ncollaboration,\\ncustomer\\nsatisfaction,\\nand\\noverall\\nproductivity.\\nSeveral\\nkey\\nfactors\\nhave\\ninfluenced\\nour\\ndecision\\nto\\nexplore\\nthis\\ntopic:\\n1.\\nRelevance\\n:\\nIn\\ntoday's\\nfast-paced\\nand\\ninterconnected\\nbusiness\\nlandscape,\\nthe\\nability\\nto\\ncommunicate\\neffectively\\nand\\nlisten\\nattentively\\nis\\ncritical\\nfor\\nnavigating\\ncomplex\\nwork\\nenvironments,\\nfostering\\npositive\\nrelationships,\\nand\\nachieving\\norganizational\\ngoals.\\nRecognizing\\nthe\\nsignificance\\nof\\nthese\\nskills,\\nour\\nteam\\nseeks\\nto\\ndelve\\ndeeper\\ninto\\ntheir\\nimplications\\nwithin\\ncorporate\\nsettings.\\n2.\\nIndustry\\nDemand\\n:\\nWith\\nthe\\nincreasing\\nemphasis\\non\\nsoft\\nskills\\nand\\nemotional\\nintelligence\\nin\\nthe\\nworkforce,\\ncommunication\\nand\\nlistening\\nabilities\\nare\\nhighly\\nsought\\nafter\\nby\\nemployers\\nacross\\nindustries.\\nBy\\ninvestigating\\nthese\\nskills'\\ndynamics\\nin\\nreal-world\\ncorporate\\ncontexts,\\nwe\\naim\\nto\\nprovide\\nvaluable\\ninsights\\nto\\nboth\\nprofessionals\\nand\\norganizations\\nstriving\\nfor\\nexcellence\\nin\\ncommunication\\npractices.\\n3.\\nPractical\\nImpact\\n:\\nPoor\\ncommunication\\nand\\nineffective\\nlistening\\ncan\\nlead\\nto\\nmisunderstandings,\\nconflicts,\\nreduced\\nproductivity,\\nand\\nultimately,\\norganizational\\ninefficiency.\\nBy\\nshedding\\nlight\\non\\nbest\\npractices,\\nchallenges,\\nand\\nstrategies\\nfor\\nenhancing\\ncommunication\\nand\\nlistening\\nskills,\\nour\\nresearch\\nendeavors\\nto\\noffer\\nactionable\\nrecommendations\\nfor\\nimproving\\nworkplace\\ndynamics\\nand\\ndriving\\npositive\\noutcomes.\\n4.\\nGap\\nin\\nKnowledge\\n:\\nDespite\\nthe\\nabundance\\nof\\nliterature\\non\\ncommunication\\nand\\nlistening\\nskills,\\nthere\\nremains\\na\\ngap\\nin\\nunderstanding\\nhow\\nthese\\nskills\\nmanifest\\nand\\nevolve\\nwithin\\nspecific\\ncorporate\\nenvironments.\\nThrough\\nempirical\\ninvestigation\\nand\\nfirsthand\\nperspectives\\nfrom\\nindustry\\nprofessionals,\\nour\\nteam\\nseeks\\nto\\naddress\\nthis\\ngap\\nby\\nproviding\\nnuanced\\ninsights\\nand\\npractical\\nimplications.\\nResearch\\nDesign\\nand\\nSample\\nSelection\\nFor\\nour\\ninvestigation\\ninto\\ncommunication\\nand\\nlistening\\nskills\\nin\\nthe\\ncorporate\\nworld,\\nwe\\nemployed\\na\\ncomprehensive\\nresearch\\ndesign\\nincorporating\\nboth\\nqualitative\\nand\\nquantitative\\ntechniques.\\nWe\\nconducted\\nsemi-structured\\ninterviews\\nwith\\nprofessionals,\\nincluding\\ntechnical\\nleads,\\nengineers\\nand\\nprofessors.\\nThese\\ninterviews\\nwere\\ndesigned\\nto\\nelicit\\nrich\\ninsights,\\nexperiences,\\nand\\nperceptions\\nregarding\\ncommunication\\nand\\nlistening\\npractices\\nwithin\\ntheir\\nrespective\\nworkplace\\ncontexts.\\nThe\\nsemi-structured\\nnature\\nof\\nthe\\ninterviews\\nallowed\\nfor\\nflexibility,\\nenabling\\nus\\nto\\nexplore\\nemerging\\nthemes\\nin-depth\\nwhile\\nensuring\\nconsistency\\nacross\\nparticipants.\", metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 2}),\n",
       " Document(page_content='In\\nour\\nsecondary\\nresearch,\\nwe\\nextensively\\nexplored\\nnews\\narticles,\\nblogs,\\nand\\nTED\\nTalks\\nto\\nenhance\\nour\\nunderstanding\\nof\\ncommunication\\nand\\nlistening\\nskills\\nin\\nthe\\ncorporate\\nworld.\\nNews\\narticles\\noffered\\nreal-world\\nexamples\\nand\\ntrends\\nacross\\nindustries,\\nwhile\\nblogs\\nprovided\\ndiverse\\nperspectives\\nand\\nexpert\\nopinions\\non\\ntopics\\nlike\\ninterpersonal\\ncommunication\\nand\\nconflict\\nresolution.\\nTED\\nTalks\\nserved\\nas\\na\\nsource\\nof\\ninspiration\\nand\\ninnovative\\nideas,\\ncovering\\ntopics\\nsuch\\nas\\nactive\\nlistening\\ntechniques\\nand\\nthe\\nrole\\nof\\nempathy\\nin\\neffective\\ncommunication.\\nBy\\nintegrating\\nthese\\nsources,\\nwe\\ngained\\na\\ncomprehensive\\nunderstanding\\nof\\ncommunication\\ndynamics,\\nenriching\\nour\\nanalysis\\nfor\\ncontemporary\\ncorporate\\nenvironments.\\nResearch\\nInsights\\nIn\\ntoday\\'s\\nfast-paced\\nand\\ninterconnected\\nworld,\\neffective\\ncommunication\\nhas\\nbecome\\nmore\\ncritical\\nthan\\never\\nfor\\nsuccess\\nin\\nboth\\npersonal\\nand\\nprofessional\\nspheres.\\nAs\\nwe\\nnavigate\\nthrough\\nthe\\nintricacies\\nof\\nthe\\ncorporate\\nlandscape,\\nit\\nbecomes\\nevident\\nthat\\ncommunication\\nmastery\\nis\\nnot\\nmerely\\na\\ndesirable\\ntrait\\nbut\\na\\nfundamental\\nnecessity.\\nThis\\nexploration\\ndelves\\ninto\\nthe\\nmultifaceted\\nnature\\nof\\ncommunication\\nskills\\nand\\nthe\\nstrategies\\nessential\\nfor\\nmastering\\nthem.\\nDrawing\\nfrom\\nan\\narray\\nof\\nresearch\\narticles,\\nTED\\nTalks,\\nand\\nscholarly\\npapers,\\nwe\\nembark\\non\\na\\njourney\\nto\\nunlock\\nthe\\npath\\nto\\ncommunication\\nexcellence.\\nIntegration\\nof\\nVerbal\\nand\\nNonverbal\\nCommunication\\nEffective\\ncommunication\\ntranscends\\nmere\\nwords;\\nit\\nencompasses\\nthe\\nseamless\\nintegration\\nof\\nverbal\\nand\\nnonverbal\\ncues.\\nResearch\\nstudies\\nsuch\\nas\\n\"What\\nDoes\\nYour\\nNonverbal\\nLanguage\\nReveal\\nAbout\\nYour\\nCommunication\\nStyle?\"\\nshed\\nlight\\non\\nthe\\nsignificance\\nof\\naligning\\nverbal\\nmessages\\nwith\\nnonverbal\\nsignals\\nfor\\nclarity\\nand\\nresonance.\\nInsights\\ngleaned\\nfrom\\nTED\\nTalks\\nlike\\nJulian\\nTreasure\\'s\\n\"How\\nto\\nSpeak\\nSo\\nThat\\nPeople\\nWant\\nto\\nListen\"\\nunderscore\\nthe\\nimportance\\nof\\ncultivating\\nan\\nawareness\\nof\\nboth\\ndimensions.\\nBy\\nhoning\\nthis\\nskill,\\nindividuals\\ncan\\nforge\\nmeaningful\\nconnections\\nand\\nnavigate\\nprofessional\\nlandscapes\\nadeptly,\\nleveraging\\nthe\\npower\\nof\\nboth\\nverbal\\nand\\nnonverbal\\ncommunication\\ncues.\\nThe\\nTransformative\\nPower\\nof\\nActive\\nListening\\nActive\\nlistening\\nemerges\\nas\\na\\ncornerstone\\nof\\neffective\\ncommunication,\\nwielding\\ntransformative\\npotential\\nin\\nvarious\\ncontexts.\\nIn\\n\"The\\nPower\\nof\\nListening:\\nHow\\nto\\nImprove\\nWorkplace\\nCommunication,\"\\nthe\\nimportance\\nof\\nactive\\nlistening\\nin\\nfostering\\ntrust,\\ncollaboration,\\nand\\nmutual\\nunderstanding\\nis\\nemphasized.\\nPractical\\nstrategies\\nsuch\\nas\\nminimizing\\ndistractions,\\nemploying\\nclarifying\\nquestions,\\nand\\nembracing\\nsilence\\ndeepen\\nengagement\\nand\\nprevent\\nmisunderstandings.\\nThrough\\nactive\\nlistening,\\nindividuals\\ncan\\ncultivate\\nempathy,\\nbuild\\nrapport,\\nand\\nfoster\\nharmonious\\nrelationships\\namong\\ncolleagues,\\nthereby\\ndriving\\norganizational\\nsuccess.', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 3}),\n",
       " Document(page_content='Leadership,\\nOrganizational\\nCulture,\\nand\\nCommunication\\nExcellence\\nLeadership\\nplays\\na\\npivotal\\nrole\\nin\\nshaping\\ncommunication\\ndynamics\\nwithin\\norganizations.\\nInsights\\nfrom\\n\"Strategic\\nCorporate\\nCommunications\"\\nunderscore\\nthe\\nsymbiotic\\nrelationship\\nbetween\\nleadership,\\norganizational\\nculture,\\nand\\ncommunication\\nexcellence.\\nEffective\\nleaders\\nare\\ndistinguished\\nby\\ntheir\\nability\\nto\\nfoster\\nopen\\ndialogue,\\nmodel\\nactive\\nlistening\\nbehaviors,\\nand\\nchampion\\ntransparent\\ncommunication\\npractices.\\nBy\\nserving\\nas\\nstewards\\nof\\ncommunication\\nexcellence,\\nleaders\\nguide\\ntheir\\nteams\\ntoward\\na\\nfuture\\ncharacterized\\nby\\nsynergy,\\ninnovation,\\nand\\ncollective\\nsuccess.\\nPractical\\nStrategies\\nfor\\nCommunication\\nEnhancement\\nOur\\nexploration\\nunveils\\na\\ntreasure\\ntrove\\nof\\npractical\\nstrategies\\nfor\\nenhancing\\ncommunication\\nskills\\namong\\nprofessionals.\\nFrom\\n\"How\\nto\\nImprove\\nInterpersonal\\nCommunication\\nin\\nthe\\nWorkplace\"\\nto\\nthe\\n\"Guide\\nto\\nBusiness\\nCommunications,\"\\nactionable\\ninsights\\nand\\nbest\\npractices\\nare\\ngleaned.\\nReal-world\\nexamples\\nand\\ncase\\nstudies\\nprovide\\ntangible\\nillustrations\\nof\\nsuccessful\\ncommunication\\ninitiatives,\\noffering\\ninvaluable\\nlessons\\nfor\\nimplementation.\\nThe\\nintegration\\nof\\ntechnology\\ninto\\ncommunication\\nprocesses\\nunderscores\\nthe\\nimperative\\nfor\\norganizations\\nto\\nembrace\\ninnovative\\ntools\\nand\\nplatforms,\\nfostering\\nefficient\\nand\\neffective\\ncommunication\\nchannels.\\nSignificance\\nof\\nListening\\nSkills\\nin\\nEnhancing\\nCommunication\\nListening\\nskills\\nemerge\\nas\\nintegral\\nto\\ncommunication\\nenhancement,\\nas\\nhighlighted\\nin\\n\"Significance\\nof\\nListening\\nSkills\\nin\\nEnhancing\\nCommunication\\nSkills.\"\\nThe\\nstudy\\nemphasizes\\nthe\\nvital\\nrole\\nof\\nlistening\\nin\\nimproving\\ncommunication\\nskills,\\nadvocating\\nfor\\npractices\\nsuch\\nas\\nactive\\nlistening\\nthrough\\nvarious\\nmeans.\\nUnderstanding\\ndifferent\\ntypes\\nof\\nlistening\\nand\\novercoming\\nbarriers\\nto\\neffective\\nlistening\\nare\\nidentified\\nas\\nkey\\nsteps\\ntoward\\nfostering\\ncommunication\\nproficiency\\namong\\nlearners.\\nBy\\nhoning\\nlistening\\nskills,\\nindividuals\\ncan\\nenhance\\ntheir\\nability\\nto\\ncomprehend,\\nempathize,\\nand\\nrespond\\nthoughtfully\\nto\\ndiverse\\nperspectives,\\nthereby\\nenriching\\ncommunication\\ninteractions.\\nThought\\nSpeed\\nand\\nEffective\\nListening\\nExploring\\nthe\\nchallenges\\nand\\nhabits\\nhindering\\neffective\\nlistening,\\nwe\\ndelve\\ninto\\nreports\\nsuch\\nas\\n\"Thought\\nSpeed\\nGreater\\nThan\\nSpeaking\\nSpeed\"\\nand\\n\"Ten\\nWorst\\nListening\\nHabits.\"\\nInsights\\ngleaned\\nfrom\\nthese\\nsources\\nshed\\nlight\\non\\nthe\\ncomplexities\\nof\\nattentive\\nlistening,\\nhighlighting\\ncommon\\nbarriers\\nand\\npitfalls.\\nAcknowledging\\nthought\\nspeed\\ndisparities\\nand\\naddressing\\nbad\\nlistening\\nhabits\\nare\\ncrucial\\nsteps\\ntoward\\nbecoming\\nmore\\nefficient\\nand\\nempathetic\\nlisteners.\\nBy\\nfostering\\nself-awareness\\nand\\nmindfulness,\\nindividuals\\ncan\\novercome\\nthese\\nobstacles\\nand\\ncultivate\\na\\ndeeper\\nconnection\\nwith\\nothers\\nthrough\\nattentive\\nlistening.', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 4}),\n",
       " Document(page_content='Communication\\nTechniques\\nfor\\nSuccess\\nLastly,\\nwe\\nexamine\\nvarious\\ncommunication\\ntechniques\\nfor\\nsuccess,\\ndrawing\\nfrom\\nTED\\nTalks\\nsuch\\nas\\nCeleste\\nHeadlee\\'s\\n\"10\\nways\\nto\\nhave\\na\\nbetter\\nconversation\"\\nand\\nMatt\\nAbrahams\\'\\n\"Think\\nFast,\\nTalk\\nSmart.\"\\nThese\\ntalks\\nunderscore\\nthe\\nimportance\\nof\\nactive\\nparticipation,\\ngenuine\\ninterest,\\nand\\neffective\\nquestioning\\nin\\nfostering\\nmeaningful\\nconversations.\\nTechniques\\nsuch\\nas\\nthe\\nHAIL\\ntechnique\\nand\\nthe\\nimportance\\nof\\ndiverse\\nvocal\\nrange\\nhighlight\\nthe\\nnuances\\nof\\neffective\\ncommunication\\nin\\ndiverse\\ncontexts.\\nBy\\nembracing\\nthese\\ntechniques,\\nindividuals\\ncan\\nenhance\\ntheir\\ncommunication\\nskills,\\nbuild\\nrapport,\\nand\\nfoster\\nproductive\\nrelationships\\nin\\nboth\\npersonal\\nand\\nprofessional\\nspheres.\\nIn\\nconclusion,\\nour\\njourney\\nthrough\\nthe\\nexpansive\\nlandscape\\nof\\ncommunication\\nand\\nlistening\\nskills\\nhas\\nprovided\\na\\nwealth\\nof\\ninsights\\nand\\npractical\\nstrategies\\nfor\\nindividuals\\nand\\norganizations\\nalike.\\nBy\\nintegrating\\nthese\\ninsights\\ninto\\nour\\ndaily\\ninteractions\\nand\\nembracing\\na\\nculture\\nof\\ncontinuous\\nlearning\\nand\\nimprovement,\\nwe\\ncan\\nunlock\\nthe\\npath\\nto\\ncommunication\\nmastery\\nand\\ndrive\\ncollective\\nsuccess\\nin\\nthe\\nprofessional\\nrealm.\\nAs\\nwe\\nnavigate\\nthe\\ncomplexities\\nof\\nthe\\ncorporate\\nlandscape,\\nlet\\nus\\nleverage\\nthe\\ntransformative\\npower\\nof\\neffective\\ncommunication\\nto\\nfoster\\ncollaboration,\\ninnovation,\\nand\\ngrowth.\\nConceptual\\nFramework\\nand\\nInfluence\\nDiagram\\n1.\\nAssessment\\nof\\nCurrent\\nCommunication\\nPractices\\n-\\nConduct\\ncomprehensive\\nsurveys\\nand\\ninterviews\\nto\\nevaluate\\nthe\\nexisting\\ncommunication\\nlandscape.\\n-\\nAnalyze\\ncommunication\\nchannels,\\ncultural\\ndynamics,\\nand\\nfeedback\\nmechanisms\\nto\\nidentify\\nareas\\nfor\\nimprovement.\\n2.\\nIntegration\\nof\\nVerbal\\nand\\nNonverbal\\nCommunication\\n-\\nFacilitate\\nworkshops\\nand\\ntraining\\nsessions\\non\\naligning\\nverbal\\nand\\nnonverbal\\ncues\\nfor\\neffective\\ncommunication.\\n-\\nDevelop\\nvisual\\naids\\nand\\ncultural\\nsensitivity\\nguides\\nto\\nenhance\\ncross-cultural\\nunderstanding.\\n-\\nEncourage\\nthe\\nuse\\nof\\nactive\\nlistening\\ntechniques\\nto\\ncomplement\\nverbal\\ncommunication\\nand\\nfoster\\nempathy.\\n3.\\nPromotion\\nof\\nActive\\nListening\\n-\\nLaunch\\ncommunication\\ncampaigns\\nemphasizing\\nthe\\nimportance\\nof\\nactive\\nlistening\\nin\\ndriving\\ncollaboration\\nand\\nproblem-solving.\\n-\\nIncorporate\\nactive\\nlistening\\nexercises\\ninto\\nteam\\nmeetings,\\nbrainstorming\\nsessions,\\nand\\ntraining\\nprograms.\\n-\\nProvide\\nresources\\nand\\ntools,\\nsuch\\nas\\nlistening\\nskills\\nworkshops\\nand\\nself-assessment\\nmodules,\\nto\\nsupport\\nongoing\\ndevelopment.\\n4.\\nLeadership\\nDevelopment\\nfor\\nCommunication\\nExcellence', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 5}),\n",
       " Document(page_content='-\\nOffer\\nleadership\\ndevelopment\\nprograms\\nfocused\\non\\ncommunication\\nskills,\\nempathy,\\nand\\nfostering\\ninclusive\\ndialogue.\\n-\\nFoster\\na\\nculture\\nof\\nopen\\ncommunication\\nand\\ntransparency\\nthrough\\nleadership\\nforums,\\ntown\\nhall\\nmeetings,\\nand\\nfeedback\\nmechanisms.\\n-\\nRecognize\\nand\\nreward\\nleaders\\nwho\\nexemplify\\neffective\\ncommunication\\npractices\\nand\\npromote\\na\\nculture\\nof\\nmutual\\nrespect\\nand\\nunderstanding.\\n5.\\nImplementation\\nof\\nPractical\\nStrategies\\n-\\nEstablish\\ncommunication\\nguidelines\\nand\\nbest\\npractices\\nto\\nstandardize\\ncommunication\\nprocesses\\nacross\\nthe\\norganization.\\n-\\nInvest\\nin\\ncommunication\\ntechnology\\nplatforms\\nto\\nfacilitate\\nseamless\\ninformation\\nsharing\\nand\\ncollaboration.\\n-\\nEncourage\\ncross-functional\\ncollaboration\\nthrough\\nproject-based\\ncommunication\\ninitiatives\\nand\\nknowledge-sharing\\nplatforms.\\n6.\\nEmphasis\\non\\nListening\\nSkills\\nEnhancement\\n-\\nProvide\\naccess\\nto\\nresources\\nsuch\\nas\\npodcasts,\\naudiobooks,\\nand\\nonline\\ncourses\\nto\\nsupport\\ncontinuous\\nlearning\\nand\\ndevelopment\\nof\\nlistening\\nskills.\\n-\\nOrganize\\nworkshops\\nand\\nseminars\\naddressing\\ncommon\\nlistening\\nbarriers\\nand\\ntechniques\\nfor\\nimproving\\nlistening\\nproficiency.\\n-\\nCultivate\\na\\nculture\\nof\\nfeedback\\nand\\nreflection,\\nencouraging\\nemployees\\nto\\nsolicit\\nand\\nact\\nupon\\nfeedback\\nto\\nenhance\\ntheir\\nlistening\\nabilities.\\n7.\\nContinuous\\nMonitoring\\nand\\nImprovement\\n-\\nEstablish\\nkey\\nperformance\\nindicators\\n(KPIs)\\nto\\nmeasure\\ncommunication\\neffectiveness,\\nemployee\\nengagement,\\nand\\ncollaboration\\nmetrics.\\n-\\nConduct\\nregular\\npulse\\nsurveys,\\nfocus\\ngroups,\\nand\\nfeedback\\nsessions\\nto\\ngather\\ninsights\\nand\\nassess\\nthe\\nimpact\\nof\\ncommunication\\ninitiatives.\\n-\\nIterate\\nand\\nrefine\\ncommunication\\nstrategies\\nbased\\non\\nfeedback,\\nevolving\\norganizational\\nneeds,\\nand\\nindustry\\nbest\\npractices.', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 6}),\n",
       " Document(page_content='A\\ndiagram\\nshowing\\nthe\\nflow\\nabove\\ncan\\nbe\\nseen\\nbelow:\\n', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 7}),\n",
       " Document(page_content=\"Project\\nReview\\nName\\nand\\nRole\\nTask\\nUndertaken\\nHari\\nPrapan\\n-\\nTEAM\\nLEAD\\n●\\nProject\\nResearch\\nand\\nApproach \\n●\\nPrimary\\n&\\nSecondary\\nresearch \\n●\\nInterview\\nof\\nPrimary\\nResource \\n●\\nPoster\\nCreation\\nPragya\\nSingh\\n-\\nTeam\\nMember\\n●\\nInterview\\nof\\nPrimary\\nResource \\n●\\nPrimary\\n&\\nSecondary\\nresearch \\n●\\nReviewed\\nall\\ndocument\\nsubmissions\\nVisist\\nTallam\\n-\\nTeam\\nMember\\n●\\nInterview\\nof\\nPrimary\\nResource \\n●\\nPrimary\\n&\\nSecondary\\nresearch \\n●\\nReviewed\\nall\\ndocument\\nsubmissions\\nUllas\\nKumar\\n-\\nTeam\\nMember\\n●\\nCompilation\\nof\\nResources \\n●\\nInterview\\nof\\nPrimary\\nResource \\n●\\nSecondary\\nresearch \\n●\\nSupported\\nfinal\\ndocument\\ncreation\\nDhruv\\nPamneja\\n-\\nTeam\\nMember\\n●\\nCreation\\nof\\nfinal\\ndocuments \\n●\\nInterview\\nof\\nPrimary\\nResource \\n●\\nSecondary\\nresearch \\n●\\nVideo\\nEditing\\nand\\nCompilation\\nLearning\\nOutcomes\\nThis\\nproject\\nserved\\nas\\na\\nplatform\\nfor\\nprofound\\nlearning\\nexperiences\\nfor\\neach\\nmember\\nof\\nour\\ngroup,\\nfocusing\\non\\nthe\\nenhancement\\nof\\ncommunication\\nskills.\\nThrough\\ndedicated\\nefforts\\nin\\nunderstanding\\nand\\nimplementing\\nvarious\\ncommunication\\nstrategies,\\nfrom\\nverbal\\nand\\nnonverbal\\nintegration\\nto\\nthe\\ntransformative\\npower\\nof\\nactive\\nlistening,\\nour\\njourney\\nwas\\na\\ncomprehensive\\nexploration\\nof\\neffective\\ncommunication\\ntechniques.\\nWe,\\nthe\\nundersigned\\nmembers\\nof\\nthe\\ngroup,\\naffirm\\nthe\\naccuracy\\nand\\nrelevance\\nof\\nthe\\nproject's\\noutcomes.\\nOur\\ncollaborative\\nendeavors\\nwere\\ndirected\\ntowards\\nachieving\\nmilestones\\nin\\ncommunication\\nproficiency,\\nand\\nwe\\nattest\\nthat\\nthe\\npresented\\noutcomes\\naccurately\\nreflect\\nour\\ncollective\\ndedication\\nand\\nachievements\\nin\\nenhancing\\ncommunication\\nwithin\\nour\\nteam.\\nSigned\\n&\\nAttested\\nHari\\nPrapan,\\nPragya\\nSingh,\\nVisist\\nTallam,\\nUllas\\nKumar,\\nDhruv\\nPamneja\", metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 8})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(\"data\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since the context window of our LLM will be limited, the ideal way to handle this is to chunk the data into paragraphs. This is done by the chunker, which takes the list of documents and returns a list of paragraphs within the chunk limit we set (500 words in this case). The chunker also takes care of the page breaks and ensures that the paragraphs are not split across pages. Also, we will be introducing an overlap, which will be the number of words that will be repeated in the end of one chunk and the beginning of the next chunk. This is done to ensure that the context is not lost between the chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should be able to do the same for text data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import last\\n\\nspark = SparkSession.builder.appName(\"SCD Type II Merge W5 GA\").getOrCreate()\\n\\nmaster_file_path = \"gs://week-5-ga/source_data-w5.csv\"\\nupdate_file_path = \"gs://week-5-ga/update_data-w5.csv\"\\noutput_file_path = \"gs://week-5-ga/master_data-w5.csv\"\\n\\nmaster_df = spark.read.csv(master_file_path, header=True, inferSchema=True)\\nupdate_df = spark.read.csv(update_file_path, header=True, inferSchema=True)\\n\\ncombined_df = master_df.union(update_df)\\n\\nfinal_df = combined_df.groupBy(\"Customer ID\").agg(\\n    last(\"Name\").alias(\"Name\"),\\n    last(\"Address\").alias(\"Address\"),\\n    last(\"Membership Start Date\").alias(\"Membership Start Date\"),\\n    last(\"Membership End Date\").alias(\"Membership End Date\")\\n)\\n\\nfinal_df.show()\\nfinal_df.write.csv(output_file_path, header=True)', metadata={'source': 'data/W5_Code.txt'})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader = TextLoader(\"data/W5_Code.txt\")\n",
    "text_data = text_loader.load()\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will have to add a page (could be 0) in the metadata on this, as it expects it to be there in the final chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import last\\n\\nspark = SparkSession.builder.appName(\"SCD Type II Merge W5 GA\").getOrCreate()\\n\\nmaster_file_path = \"gs://week-5-ga/source_data-w5.csv\"\\nupdate_file_path = \"gs://week-5-ga/update_data-w5.csv\"\\noutput_file_path = \"gs://week-5-ga/master_data-w5.csv\"\\n\\nmaster_df = spark.read.csv(master_file_path, header=True, inferSchema=True)\\nupdate_df = spark.read.csv(update_file_path, header=True, inferSchema=True)\\n\\ncombined_df = master_df.union(update_df)\\n\\nfinal_df = combined_df.groupBy(\"Customer ID\").agg(\\n    last(\"Name\").alias(\"Name\"),\\n    last(\"Address\").alias(\"Address\"),\\n    last(\"Membership Start Date\").alias(\"Membership Start Date\"),\\n    last(\"Membership End Date\").alias(\"Membership End Date\")\\n)\\n\\nfinal_df.show()\\nfinal_df.write.csv(output_file_path, header=True)', metadata={'source': 'data/W5_Code.txt', 'page': 0})]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[0].metadata[\"page\"] = 0\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, this chunk will follow the exact same steps as the PDF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Project\\nReport\\nSPG\\nGroup\\nProject\\nJan\\n2024\\nCommunication\\nand\\nListening\\nSkills\\nTeam\\n5\\nTeam\\nMembers\\nHari\\nPrapan\\n(21f3002087)\\nPragya\\nSingh\\n(21f3001204)\\nVisist\\nTallam\\n(21f2001553)\\nUllas\\nKumar\\n(21f3002619)\\nDhruv\\nPamneja\\n(21f1001719)', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 0}),\n",
       " Document(page_content=\"Abstract\\nThe\\nproject\\nfocuses\\non\\nexploring\\nthe\\ncritical\\nimportance\\nof\\ncommunication\\nand\\nlistening\\nskills\\nwithin\\nthe\\ncorporate\\nworld.\\nIt\\ndelves\\ninto\\nthe\\nfoundational\\nrole\\nthese\\nskills\\nplay\\nin\\norganizational\\nsuccess,\\nimpacting\\nareas\\nsuch\\nas\\nemployee\\nengagement,\\nteam\\ncollaboration,\\nand\\noverall\\nproductivity.\\nThe\\ndecision\\nto\\ninvestigate\\nthis\\ntopic\\nstems\\nfrom\\nits\\nrelevance\\nin\\ntoday's\\nfast-paced\\nbusiness\\nlandscape,\\nwhere\\neffective\\ncommunication\\nis\\nvital\\nfor\\nnavigating\\ncomplex\\nenvironments\\nand\\nachieving\", metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 1}),\n",
       " Document(page_content='and\\nachieving\\norganizational\\ngoals.\\nBy\\nconducting\\nsemi-structured\\ninterviews\\nwith\\nprofessionals\\nand\\nextensively\\nresearching\\nrelevant\\nliterature,\\nthe\\nproject\\naims\\nto\\nprovide\\nvaluable\\ninsights\\nand\\npractical\\nrecommendations\\nfor\\nenhancing\\ncommunication\\npractices\\nin\\ncorporate\\nsettings.\\nThe\\nconceptual\\nframework\\noutlines\\nkey\\nstrategies\\nfor\\nimproving\\ncommunication\\neffectiveness,\\nleadership\\ndevelopment,\\nand\\ncontinuous\\nmonitoring\\nand\\nimprovement.\\nThrough\\ncollaborative\\nefforts,\\nthe\\nproject\\ncontributes\\nto', metadata={'source': 'data/Team_5_SPG_GP2_Report_Jan_2024.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_split = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "text_chunks = text_split.split_documents(data)\n",
    "\n",
    "\n",
    "text_chunks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each of our chunks is in the limit of 500 characters and the overlap is 20 characters, let us view the total number of chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of chunks : 37\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of chunks : {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone Initialization\n",
    "Now, we will be using the pinecone vectorDB to store the embeddings of the chunks. We will be using the `pinecone.init()` function to initialize the pinecone environment. We will be using the `pinecone.use_index()` function to use the index created for this project and setup the instance for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key = PINECONE_API_KEY, environment = PINECONE_API_ENV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us view the indexs avaliable in the pinecone environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 1536,\n",
       "              'host': 'documents-f1hj4e6.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'documents',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is the one we will be using for storing the documnets of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Chunks using OpenAI text-embedding-3-small\n",
    "Here, we will be using the OpenAI text-embedding-3-small model to embed the chunks, for which we will need an openAI instance initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go ahead and set the embeddings model and a function to get the embeddings of any given text via the text-embedding-3-small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = openAI_client.embeddings\n",
    "\n",
    "def get_embedding(text) :\n",
    "    response = embedding_model.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each chunk will ideally below to a documnent stored in S3 bucket in AWS. So, for now we will assume that the **KEY** of that document is in the format as given below which we will be using in the metadata. To simiplify the process, each entry in the vectorDB should have : \n",
    "\n",
    "* **ID** : The unique ID of the document, which will be a combination of the document key and the chunk number.\n",
    "* **VALUES** : The embedding of the chunk, as generated by the OpenAI text-embedding-3-small model.\n",
    "* **METADATA** : The metadata of the document, which will include the document key and the chunk number.\n",
    "    *  **USER_ID** : The ID of the user in our system.\n",
    "    *  **DOCUMENT_TYPE** : The type of the document from either \"pdf\" or \"text\".\n",
    "    *  **KEY** : The key of the document in the S3 bucket, which defines the location of the document.\n",
    "    *  **CHUNK** : The text of the chunk.\n",
    "    *  **PAGE_NUMBER** : The page number of the chunk in the document.\n",
    "    *  **CHUNK_INDEX** : The number of the chunk in the document.\n",
    "\n",
    "Since most of the information will be given by the backend server, for now we will use dummy values for the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"61f100abx/pdf/projectReport\"\n",
    "USER_ID = \"61f100abx\"\n",
    "DOCUMENT_TYPE = \"pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create the function to create vectors in our desired format as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(text_chunks,KEY,USER_ID,DOCUMENT_TYPE):\n",
    "    v = []\n",
    "    chunk_num = 0\n",
    "    \n",
    "    for chunk in text_chunks: \n",
    "        page_num = chunk.metadata[\"page\"]\n",
    "        \n",
    "        entry = {}\n",
    "        entry[\"id\"] = f\"{KEY}_PAGE_{page_num}_CHUNK_{chunk_num}\"\n",
    "        entry[\"values\"] = get_embedding(chunk.page_content)\n",
    "        entry[\"metadata\"] = {\n",
    "            \"userID\" : USER_ID,\n",
    "            \"type\" : DOCUMENT_TYPE,\n",
    "            \"key\" : KEY,\n",
    "            \"chunk\" : chunk.page_content,\n",
    "            \"page_number\" : chunk.metadata[\"page\"],\n",
    "            \"chunk_number\" : chunk_num\n",
    "        }\n",
    "        \n",
    "        chunk_num += 1\n",
    "        v.append(entry)\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = create_vectors(text_chunks,KEY,USER_ID,DOCUMENT_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have our vectors stored in the ideal format to be pushed into the vector DB. Let us now push the vectors into the vectorDB of pinecone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing the Vectors into the Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 37}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"documents\"\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "index.upsert(\n",
    "    vectors=vectors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Vectors\n",
    "We shall now query the vectors to check if the vectors have been stored correctly in the pinecone index, and how does this exactly work. We will fetch the relevant vectors from the pinecone index. For that, we will create a function which takes a text query, converts into to an embedding and queries the pinecone index to get the most similar texts from the vectors stored in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_chunks(query,userID,KEY):\n",
    "    query_vector = get_embedding(query)\n",
    "    \n",
    "    results = index.query(\n",
    "        vector = query_vector,\n",
    "        top_k = 5,\n",
    "        include_values = False,\n",
    "        include_metadata = True,\n",
    "        filter={\n",
    "            \"userID\" : userID,\n",
    "            \"key\" : KEY\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    relevant_texts = []\n",
    "    for record in results['matches']:\n",
    "        text = {}\n",
    "        text['score'] = record['score']\n",
    "        text['text'] = record['metadata']['chunk']\n",
    "        text[\"reference\"] = int(record[\"metadata\"][\"page_number\"]) + 1\n",
    "        relevant_texts.append(text)\n",
    "    \n",
    "    return relevant_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a QA system which will take a query and return the most relevant chunks from the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0.353432596 \n",
      " Reference 9 \n",
      " Answer: \n",
      " Project\n",
      "Review\n",
      "Name\n",
      "and\n",
      "Role\n",
      "Task\n",
      "Undertaken\n",
      "Hari\n",
      "Prapan\n",
      "-\n",
      "TEAM\n",
      "LEAD\n",
      "●\n",
      "Project\n",
      "Research\n",
      "and\n",
      "Approach \n",
      "●\n",
      "Primary\n",
      "&\n",
      "Secondary\n",
      "research \n",
      "●\n",
      "Interview\n",
      "of\n",
      "Primary\n",
      "Resource \n",
      "●\n",
      "Poster\n",
      "Creation\n",
      "Pragya\n",
      "Singh\n",
      "-\n",
      "Team\n",
      "Member\n",
      "●\n",
      "Interview\n",
      "of\n",
      "Primary\n",
      "Resource \n",
      "●\n",
      "Primary\n",
      "&\n",
      "Secondary\n",
      "research \n",
      "●\n",
      "Reviewed\n",
      "all\n",
      "document\n",
      "submissions\n",
      "Visist\n",
      "Tallam\n",
      "-\n",
      "Team\n",
      "Member\n",
      "●\n",
      "Interview\n",
      "of\n",
      "Primary\n",
      "Resource \n",
      "●\n",
      "Primary\n",
      "&\n",
      "Secondary\n",
      "research \n",
      "●\n",
      "Reviewed\n",
      "all\n",
      "document\n",
      "submissions\n",
      "Ullas\n",
      "Kumar\n",
      "-\n",
      "Team\n",
      "Member\n",
      "●\n",
      "Compilation\n",
      "of\n",
      "Resources \n",
      "●\n",
      "------------------------\n",
      "Rank 0.347688705 \n",
      " Reference 9 \n",
      " Answer: \n",
      " dedication\n",
      "and\n",
      "achievements\n",
      "in\n",
      "enhancing\n",
      "communication\n",
      "within\n",
      "our\n",
      "team.\n",
      "Signed\n",
      "&\n",
      "Attested\n",
      "Hari\n",
      "Prapan,\n",
      "Pragya\n",
      "Singh,\n",
      "Visist\n",
      "Tallam,\n",
      "Ullas\n",
      "Kumar,\n",
      "Dhruv\n",
      "Pamneja\n",
      "------------------------\n",
      "Rank 0.319635719 \n",
      " Reference 3 \n",
      " Answer: \n",
      " perspectives\n",
      "from\n",
      "industry\n",
      "professionals,\n",
      "our\n",
      "team\n",
      "seeks\n",
      "to\n",
      "address\n",
      "this\n",
      "gap\n",
      "by\n",
      "providing\n",
      "nuanced\n",
      "insights\n",
      "and\n",
      "practical\n",
      "implications.\n",
      "Research\n",
      "Design\n",
      "and\n",
      "Sample\n",
      "Selection\n",
      "For\n",
      "our\n",
      "investigation\n",
      "into\n",
      "communication\n",
      "and\n",
      "listening\n",
      "skills\n",
      "in\n",
      "the\n",
      "corporate\n",
      "world,\n",
      "we\n",
      "employed\n",
      "a\n",
      "comprehensive\n",
      "research\n",
      "design\n",
      "incorporating\n",
      "both\n",
      "qualitative\n",
      "and\n",
      "quantitative\n",
      "techniques.\n",
      "We\n",
      "conducted\n",
      "semi-structured\n",
      "interviews\n",
      "with\n",
      "professionals,\n",
      "including\n",
      "technical\n",
      "leads,\n",
      "engineers\n",
      "and\n",
      "professors.\n",
      "These\n",
      "interviews\n",
      "were\n",
      "------------------------\n",
      "Rank 0.317676961 \n",
      " Reference 5 \n",
      " Answer: \n",
      " Leadership,\n",
      "Organizational\n",
      "Culture,\n",
      "and\n",
      "Communication\n",
      "Excellence\n",
      "Leadership\n",
      "plays\n",
      "a\n",
      "pivotal\n",
      "role\n",
      "in\n",
      "shaping\n",
      "communication\n",
      "dynamics\n",
      "within\n",
      "organizations.\n",
      "Insights\n",
      "from\n",
      "\"Strategic\n",
      "Corporate\n",
      "Communications\"\n",
      "underscore\n",
      "the\n",
      "symbiotic\n",
      "relationship\n",
      "between\n",
      "leadership,\n",
      "organizational\n",
      "culture,\n",
      "and\n",
      "communication\n",
      "excellence.\n",
      "Effective\n",
      "leaders\n",
      "are\n",
      "distinguished\n",
      "by\n",
      "their\n",
      "ability\n",
      "to\n",
      "foster\n",
      "open\n",
      "dialogue,\n",
      "model\n",
      "active\n",
      "listening\n",
      "behaviors,\n",
      "and\n",
      "champion\n",
      "transparent\n",
      "communication\n",
      "practices.\n",
      "By\n",
      "serving\n",
      "as\n",
      "stewards\n",
      "------------------------\n",
      "Rank 0.309471667 \n",
      " Reference 6 \n",
      " Answer: \n",
      " complement\n",
      "verbal\n",
      "communication\n",
      "and\n",
      "foster\n",
      "empathy.\n",
      "3.\n",
      "Promotion\n",
      "of\n",
      "Active\n",
      "Listening\n",
      "-\n",
      "Launch\n",
      "communication\n",
      "campaigns\n",
      "emphasizing\n",
      "the\n",
      "importance\n",
      "of\n",
      "active\n",
      "listening\n",
      "in\n",
      "driving\n",
      "collaboration\n",
      "and\n",
      "problem-solving.\n",
      "-\n",
      "Incorporate\n",
      "active\n",
      "listening\n",
      "exercises\n",
      "into\n",
      "team\n",
      "meetings,\n",
      "brainstorming\n",
      "sessions,\n",
      "and\n",
      "training\n",
      "programs.\n",
      "-\n",
      "Provide\n",
      "resources\n",
      "and\n",
      "tools,\n",
      "such\n",
      "as\n",
      "listening\n",
      "skills\n",
      "workshops\n",
      "and\n",
      "self-assessment\n",
      "modules,\n",
      "to\n",
      "support\n",
      "ongoing\n",
      "development.\n",
      "4.\n",
      "Leadership\n",
      "Development\n",
      "for\n",
      "Communication\n",
      "------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "while True:\n",
    "    user_input = input(f\"Input Prompt: \")\n",
    "    if user_input=='exit':\n",
    "        print( 'Exiting')\n",
    "        sys.exit()\n",
    "    if user_input == '':\n",
    "        continue\n",
    "    \n",
    "    docs = get_relevant_chunks(user_input,USER_ID,KEY)\n",
    "        \n",
    "    for doc in docs:\n",
    "        print(f\"Rank {doc['score']} \\n Reference {doc['reference']} \\n Answer: \\n {doc['text']}\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, our pipeline is complete and we can now move on to the next steps which is sending these relvant documents to the LLM to answer our query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template for the LLM\n",
    "Here, we will need to define the prompt for the LLM to answer the query. The LLM will be given the query and the relevant documents, and it will be expected to return the answer to the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_template = \"\"\"\n",
    "    You are a specialised AI document analyser, and you will be assisting the users to answer their queries. You will be given \n",
    "    the top relevant documents and you have to use those to answer the query asked by the user, which will be given to you below. \n",
    "    In the relevant documents,you will be given the cosine similarity score, the reference (which is the page number where this \n",
    "    text was in the document) and the text itself. You can in you answer integrate the reference to build authenticity of your answer, \n",
    "    by precisely writing it like (reference page : page_num)\n",
    "    \n",
    "    \\n\\n User Query : {query}\n",
    "    \\n\\n Documents : {documents}\n",
    "    \n",
    "    MAKE SURE YOU DO NOT ANSWER FROM ANYTHING APART FROM THE DOCUMENTS GIVEN TO YOU. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\",\"documents\"],\n",
    "    template=query_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the LLM Client and Chain for RAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature = 0,  \n",
    "    model = \"gpt-4o\",\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=query_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A System using the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM:\n",
      "The compilation of resources and final documents was primarily handled by Ullas Kumar and Dhruv Pamneja. Ullas Kumar was responsible for the compilation of resources, while Dhruv Pamneja worked on the creation of the final documents (reference page: 9).\n",
      "\n",
      "Here are the details and roll numbers of the team members involved:\n",
      "\n",
      "- Hari Prapan (21f3002087) - Team Lead\n",
      "- Pragya Singh (21f3001204) - Team Member\n",
      "- Visist Tallam (21f2001553) - Team Member\n",
      "- Ullas Kumar (21f3002619) - Team Member\n",
      "- Dhruv Pamneja (21f1001719) - Team Member (reference page: 1)\n"
     ]
    }
   ],
   "source": [
    "user_query = \"who worked on the compliation of the resources and final documents? tell me their details and roll numbers?\"\n",
    "docs = get_relevant_chunks(user_query,USER_ID,KEY)\n",
    "\n",
    "# Run the chain\n",
    "response = query_chain.invoke({\n",
    "    \"query\": user_query,\n",
    "    \"documents\": docs\n",
    "})\n",
    "\n",
    "# Print the response\n",
    "print(\"Response from LLM:\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have successfully built the RAG model and the Q&A system using the chain. With this, we get the functionality to query the relevant documents and get the answer to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting via Pinecone (Listing indexes with prefix and then deleting the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"documents\"\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "list1 = []\n",
    "for ids in index.list(prefix=KEY):\n",
    "  list1.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEY = \"674313bc5cbbf2d8da2a4649/pdf/\"\n",
    "res = index.delete([ids for ids in index.list(prefix=KEY)])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
