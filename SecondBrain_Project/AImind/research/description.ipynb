{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import tempfile\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Instance\n",
    "Since this is a pretty basic functionality, we would be passing the link of the given PDF to generate the summary description of the PDF. For that, we will first initialize the LLM instance using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a document summarizer. Give a short (1-2) line summarisation of the given text chunks as a list, where each chunk represents a page\n",
    "of that PDF. Note that do not exceed more than 25-30 words, do not give a summary in bullet points but rather a sentence or two.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21F1001719BS in Data Science and ApplicationsDIPLOMADHRUV PAMNEJA\\nhttps://study.iitm.ac.in/ds/Jan 2024 - Dec 2024B +ve\\n2000-11-25New Delhi,Delhi-(National-Capital-Territory),INDIA - 110026Punjabi Bagh West36/75, Swastika Apartments, Behind NC Jindal Public Sc hool+919958841734']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"https://100xbrainly.s3.ap-south-1.amazonaws.com/674313bc5cbbf2d8da2a4649/pdf/IDCARD?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA3FLD6D7YF43TOFAG%2F20241206%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20241206T105326Z&X-Amz-Expires=3600&X-Amz-Signature=748baf73da51f029e1f6cde59dd8158095c8b324e241e730a35f028a2aae29c1&X-Amz-SignedHeaders=host&x-id=GetObject\")\n",
    "data = loader.load()\n",
    "chunks = []\n",
    "for doc in data:\n",
    "    chunks.append(doc.page_content)\n",
    "    \n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can generate a summary of the given text chunks. We can use the LLM instance to generate the summary of the given text chunks. Before that, let us also check the same for a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as temp_file:\n",
    "            temp_file.write(response.text)\n",
    "            temp_file_path = temp_file.name\n",
    "        \n",
    "        loader = TextLoader(temp_file_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading text from URL: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        import os\n",
    "        if 'temp_file_path' in locals():\n",
    "            os.unlink(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ï»¿LxI 1.1 - Reflection Quiz 1 - Part C \\n\\n\\n1. I choose to explore the Zomato application for my answer. The two components that I wrote about in my answer are: \\n\\n\\n   1. User Interface (UI)\\n   2. Backend Server\\n\\n\\nI chose these two as these were the first components which came to my mind as I thought about the primary features/components of this application. The interaction of these components assimilates into a key functionality of the application and serves as a major component of providing a smooth user experience. \\n\\n\\n2. Although most of the posts have been quite informative in that sense, the post I found the most interesting was Saurav Sharma's Post, this is so as I found it perfectly captured the front-end and back-end working of the application and encompassed a whole picture of the SBI Banking application, at least a macro level. Of course a lot of additional information and components are there to be mentioned, but this post encouraged me to design and capture holistic components and their interaction in my answer. \\n\\n\\n3. I have responded to two posts, which are as follows:\\n   1. Sashi Adhithya R's Post\\n   2. Rishita Pathak's Post\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = load_text_from_url(\"https://100xbrainly.s3.ap-south-1.amazonaws.com/674313bc5cbbf2d8da2a4649/text/testDoc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA3FLD6D7YF43TOFAG%2F20241206%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20241206T105429Z&X-Amz-Expires=3600&X-Amz-Signature=2de5df680367a422a9a789bcdeb6d29de7ab61d9c2dfc36dbb0ea234874448d3&X-Amz-SignedHeaders=host&x-id=GetObject\")\n",
    "text_chunks = [doc[0].page_content]\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the next step would be identical for both the PDF and text files. We will pass the text chunks to the LLM instance to generate the summary of the given text chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : [\n",
    "                {\n",
    "                    \"type\" : \"text\",\n",
    "                    \"text\" : prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": str(text_chunks)\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author reflects on the Zomato application, focusing on its User Interface and Backend Server as key components for user experience, while also appreciating a peer's insightful analysis of the SBI Banking application. Additionally, they mention responding to two classmates' posts.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we are able to build a flow by which the LLM instance can be used to generate the summary of the given PDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
